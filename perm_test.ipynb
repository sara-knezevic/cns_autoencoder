{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from utils.Preprocessing import Preprocessing\n",
    "from utils.metrics import compute_fc_matrix_regular\n",
    "import matplotlib.pyplot as plt\n",
    "from networks.Autoencoder import Autoencoder\n",
    "from scipy.stats import zscore\n",
    "import utils.utils as utils\n",
    "import seaborn as sns\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import pandas as pd\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the classifier\n",
    "classifier_original = torch.load(f'./models/DT_original_data.pt')\n",
    "classifier_reconstructed = torch.load(f'./models/DT_reconstructed_data.pt')\n",
    "classifier_latent = torch.load(f'./models/DT_latent_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=80, out_features=256, bias=True)\n",
       "    (1): Dropout(p=0.2, inplace=False)\n",
       "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (4): Dropout(p=0.1, inplace=False)\n",
       "    (5): ReLU()\n",
       "    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Linear(in_features=128, out_features=18, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=18, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): Linear(in_features=256, out_features=80, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = Preprocessing()\n",
    "mat_data = loadmat('./data/laufs_sleep.mat')\n",
    "assert mat_data['TS_N1'].shape == mat_data['TS_N2'].shape == mat_data['TS_N3'].shape == mat_data['TS_W'].shape\n",
    "wake_data = mat_data['TS_W'][0][1:]\n",
    "n3_data = mat_data['TS_N3'][0][1:]\n",
    "\n",
    "wake_data_shortened, _ = preprocessor.shorten_data(wake_data, final_length=200)\n",
    "n3_data_shortened, _ = preprocessor.shorten_data(n3_data, final_length=200)\n",
    "\n",
    "concatenated_data = np.concatenate([wake_data_shortened, n3_data_shortened])\n",
    "concatenated_data = zscore(concatenated_data)\n",
    "\n",
    "wake_data_norm = concatenated_data[:wake_data_shortened.shape[0]]\n",
    "n3_data_norm = concatenated_data[wake_data_shortened.shape[0]:]\n",
    "\n",
    "wake_data_reshaped = wake_data_norm.reshape(-1, 80)\n",
    "n3_data_reshaped = n3_data_norm.reshape(-1, 80)\n",
    "\n",
    "num_time_points = 200\n",
    "num_brain_nodes = 80\n",
    "\n",
    "wake_labels = torch.zeros((wake_data_shortened.shape[0], 1))\n",
    "n3_labels = torch.ones((n3_data_shortened.shape[0], 1))\n",
    "\n",
    "valid_labels = torch.cat((wake_labels, n3_labels), 0)\n",
    "\n",
    "wake_num_participants = wake_data_reshaped.shape[0] // num_time_points\n",
    "n3_num_participants = n3_data_reshaped.shape[0] // num_time_points\n",
    "\n",
    "wake_data_tensor = torch.tensor(wake_data_reshaped, dtype=torch.float32).reshape(wake_num_participants, num_time_points, num_brain_nodes)\n",
    "n3_data_tensor = torch.tensor(n3_data_reshaped, dtype=torch.float32).reshape(n3_num_participants, num_time_points, num_brain_nodes)\n",
    "\n",
    "assert wake_data_tensor.shape[0] == wake_data_shortened.shape[0]\n",
    "assert n3_data_tensor.shape[0] == n3_data_shortened.shape[0]\n",
    "\n",
    "latent_dimension = 18\n",
    "model = Autoencoder(latent_dim=latent_dimension)\n",
    "model.load_state_dict(torch.load(f'./models/doubleDropout/AE_results_lat{latent_dimension}.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PERMUTATION TEST FOR CLASSIFIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data: (score) 0.860, (p-value) 0.003\n",
      "Reconstructed data: (score) 0.893, (p-value) 0.001\n",
      "Latent data: (score) 0.827, (p-value) 0.007\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import permutation_test_score\n",
    "\n",
    "with torch.no_grad():\n",
    "    num_wake = wake_data_tensor.shape[0]\n",
    "    reconstructed_wake, latent_wake = model(wake_data_tensor.view(-1, num_brain_nodes))\n",
    "    latent_wake_data = latent_wake.view(num_wake, num_time_points, latent_dimension)\n",
    "    reconstructed_wake = reconstructed_wake.view(num_wake, num_time_points, num_brain_nodes)\n",
    "\n",
    "    num_n3 = n3_data_tensor.shape[0]\n",
    "    reconstructed_n3, latent_n3 = model(n3_data_tensor.view(-1, num_brain_nodes))\n",
    "    latent_n3_data = latent_n3.view(num_n3, num_time_points, latent_dimension)\n",
    "    reconstructed_n3 = reconstructed_n3.view(num_n3, num_time_points, num_brain_nodes)\n",
    "\n",
    "num_participants = num_wake + num_n3\n",
    "\n",
    "original_correlation_matrices = torch.empty(num_participants, 80, 80)\n",
    "latent_correlation_matrices = torch.empty(num_participants, latent_dimension, latent_dimension)\n",
    "reconstructed_correlation_matrices = torch.empty(num_participants, 80, 80)\n",
    "\n",
    "data_tensor = torch.cat([wake_data_tensor, n3_data_tensor], dim=0)\n",
    "latent_data = torch.cat([latent_wake_data, latent_n3_data], dim=0)\n",
    "reconstructed_data = torch.cat([reconstructed_wake, reconstructed_n3], dim=0)\n",
    "\n",
    "for i in range(num_participants):\n",
    "    # Original Correlation Matrix\n",
    "    participant_data = data_tensor[i]\n",
    "    participant_data_tensor = participant_data.clone().detach()\n",
    "    original_correlation_matrix = compute_fc_matrix_regular(participant_data_tensor)\n",
    "\n",
    "    original_correlation_matrices[i] = original_correlation_matrix\n",
    "\n",
    "    # Latent Correlation Matrix\n",
    "    participant_latent_data = latent_data[i]\n",
    "    participant_latent_data_tensor = participant_latent_data.clone().detach()\n",
    "    latent_correlation_matrix = compute_fc_matrix_regular(participant_latent_data_tensor, num_brain_nodes=latent_dimension)\n",
    "\n",
    "    latent_correlation_matrices[i] = latent_correlation_matrix\n",
    "\n",
    "    # Reconstructed Correlation Matrix\n",
    "    participant_reconstructed_data = reconstructed_data[i]\n",
    "    participant_reconstructed_data_tensor = participant_reconstructed_data.clone().detach()\n",
    "    reconstructed_correlation_matrix = compute_fc_matrix_regular(participant_reconstructed_data_tensor)\n",
    "\n",
    "    reconstructed_correlation_matrices[i] = reconstructed_correlation_matrix\n",
    "\n",
    "original_lower_triangles = torch.stack([torch.tensor(utils.extract_lower_triangle(mat.numpy())) for mat in original_correlation_matrices])\n",
    "latent_lower_triangles = torch.stack([torch.tensor(utils.extract_lower_triangle(mat.numpy())) for mat in latent_correlation_matrices])\n",
    "reconstructed_lower_triangles = torch.stack([torch.tensor(utils.extract_lower_triangle(mat.numpy())) for mat in reconstructed_correlation_matrices])\n",
    "\n",
    "score_original, permutation_scores_original, p_value_original = permutation_test_score(\n",
    "    classifier_original, original_lower_triangles, valid_labels, n_permutations=1000, n_jobs=-1, random_state=42,\n",
    ")\n",
    "\n",
    "score_reconstructed, permutation_scores_reconstructed, p_value_reconstructed = permutation_test_score(\n",
    "    classifier_reconstructed, reconstructed_lower_triangles, valid_labels, n_permutations=1000, n_jobs=-1, random_state=42,\n",
    ")\n",
    "\n",
    "score_latent, permutation_scores_latent, p_value_latent = permutation_test_score(\n",
    "    classifier_latent, latent_lower_triangles, valid_labels, n_permutations=1000, n_jobs=-1, random_state=42\n",
    ")\n",
    "\n",
    "print (f'Original data: (score) {score_original:.3f}, (p-value) {p_value_original:.3f}')\n",
    "print (f'Reconstructed data: (score) {score_reconstructed:.3f}, (p-value) {p_value_reconstructed:.3f}')\n",
    "print (f'Latent data: (score) {score_latent:.3f}, (p-value) {p_value_latent:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
